{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"titanic\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.csv('./train.csv', header=\"true\", inferSchema=\"true\")\n",
    "test = spark.read.csv('./test.csv', header=\"true\", inferSchema=\"true\")\n",
    "\n",
    "train.printSchema()\n",
    "test.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will explore missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 0.8013468013468014),\n",
       " ('Cabin', 0.22895622895622897),\n",
       " ('Embarked', 0.9977553310886644)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Find columns with missing values\n",
    "def findNullColumns(df):\n",
    "    nullCols = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        notNullCount = df.filter(col(k).isNotNull()).count()\n",
    "        if df.filter(col(k).isNotNull()).count() != numRows:\n",
    "            nullCols.append((k, notNullCount/numRows))\n",
    "    return nullCols\n",
    "\n",
    "findNullColumns(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see almost 80% of Cabin column is missing data. So we will drop the Cabin column.\n",
    "Very few data is missing in Embarked column. We will just drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.filter(train.Age.isNotNull())\n",
    "train = train.filter(train.Embarked.isNotNull())\n",
    "train = train.drop('Cabin')\n",
    "train.printSchema()\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next few sections, we will explore training data and the relationship between different features and labels.\n",
    "As we already know, most of passengers in Titanic didn't survive. Our training data suggests the same, around one-third of the passengers survived. Same goes for passenger class and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  288|\n",
      "|       0|  424|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelCol = 'Survived'\n",
    "train.groupby(labelCol).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+\n",
      "|Survived_Sex|female|male|\n",
      "+------------+------+----+\n",
      "|           1|   195|  93|\n",
      "|           0|    64| 360|\n",
      "+------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Sex').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+---+---+\n",
      "|Survived_Pclass|  1|  2|  3|\n",
      "+---------------+---+---+---+\n",
      "|              1|120| 83| 85|\n",
      "|              0| 64| 90|270|\n",
      "+---------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Pclass').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+---+---+\n",
      "|Survived_Embarked|  C|  Q|  S|\n",
      "+-----------------+---+---+---+\n",
      "|                1| 79|  8|201|\n",
      "|                0| 51| 20|353|\n",
      "+-----------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Embarked').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---+---+---+---+---+\n",
      "|Survived_SibSp|  0|  1|  2|  3|  4|  5|\n",
      "+--------------+---+---+---+---+---+---+\n",
      "|             1|173| 97| 11|  4|  3|  0|\n",
      "|             0|296| 86| 14|  8| 15|  5|\n",
      "+--------------+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'SibSp').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---+---+---+---+---+---+\n",
      "|Survived_Parch|  0|  1|  2|  3|  4|  5|  6|\n",
      "+--------------+---+---+---+---+---+---+---+\n",
      "|             1|184| 61| 39|  3|  0|  1|  0|\n",
      "|             0|335| 49| 29|  2|  4|  4|  1|\n",
      "+--------------+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Parch').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValues: [0.0,0.0,2.20492079113e-05,1.77768084808e-07,3.85649068235e-10,0.0079661893038,0.0585407002562,0.000241822421437,0.0262025008769,0.826666285255,0.246113435072]\n",
      "degreesOfFreedom: [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "statistics: [91.0807454879,205.136484693,18.003561393,27.2609222767,39.1841969013,7.04105949671,3.57825258256,13.4745403708,4.94260609943,0.0479518705244,1.34523178728]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark.ml.feature import Bucketizer, OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorIndexer\n",
    "\n",
    "edaEmbarkedIndexer = StringIndexer(inputCol='Embarked', outputCol='indexedEmbarked')\n",
    "edaSexIndexer = StringIndexer(inputCol='Sex', outputCol='indexedSex')\n",
    "\n",
    "ageSplits = [0, 16, 32, 48, 64, 200]\n",
    "edaAgeBucketizer = Bucketizer(splits=ageSplits, inputCol='Age', outputCol='bucketedAge')\n",
    "\n",
    "fareSplits = [-float('inf'), 7.91, 14.454, 31, float('inf')]\n",
    "edaFareBucketizer = Bucketizer(splits=fareSplits, inputCol='Fare', outputCol='bucketedFare')\n",
    "\n",
    "oneHotEncoderEstimator = OneHotEncoderEstimator(inputCols=['indexedSex', 'indexedEmbarked', 'bucketedFare', 'bucketedAge'], \n",
    "                                                outputCols=['oneHotSex', 'oneHotEmbarked','oneHotFare', 'oneHotAge'])\n",
    "inputCols=['Pclass', 'oneHotSex', 'oneHotEmbarked','oneHotFare', 'oneHotAge']\n",
    "edaAssembler = VectorAssembler(inputCols=inputCols, outputCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages=[edaEmbarkedIndexer, edaSexIndexer, edaAgeBucketizer, \n",
    "                            edaFareBucketizer, oneHotEncoderEstimator, edaAssembler])\n",
    "chiSqTrain = pipeline.fit(train).transform(train)\n",
    "\n",
    "r = ChiSquareTest.test(chiSqTrain, 'features', 'Survived').head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "embarkedIndexer = StringIndexer(inputCol='Embarked', outputCol='indexedEmbarked', handleInvalid='skip')\n",
    "sexFeatureIndexer = StringIndexer(inputCol='Sex', outputCol='indexedSex', handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "ageSplits = [0, 16, 32, 48, 64, 200]\n",
    "ageBucketizer = Bucketizer(splits=ageSplits, inputCol='Age', outputCol='bucketedAge', handleInvalid='skip')\n",
    "fareSplits = [-float('inf'), 7.91, 14.454, 31, float('inf')]\n",
    "fareBucketizer = Bucketizer(splits=fareSplits, inputCol='Fare', outputCol='bucketedFare', handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "oneHotEncoderEstimator = OneHotEncoderEstimator(inputCols=['indexedSex', 'indexedEmbarked', 'bucketedFare', 'bucketedAge'], \n",
    "                                                outputCols=['oneHotSex', 'oneHotEmbarked','oneHotFare', 'oneHotAge'])\n",
    "assembler = VectorAssembler(inputCols=['Pclass', 'SibSp', 'Parch', 'bucketedAge', \n",
    "                                       'bucketedFare', 'indexedEmbarked', 'indexedSex'], outputCol='features')\n",
    "rf = RandomForestClassifier(labelCol=labelCol, featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[embarkedIndexer, sexFeatureIndexer, ageBucketizer, \n",
    "                            fareBucketizer, oneHotEncoderEstimator, assembler, rf])\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(rf.numTrees, [15, 20, 25, 30]).addGrid(rf.maxDepth, [3, 5]).build()\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=BinaryClassificationEvaluator(labelCol=labelCol, metricName='areaUnderROC'), \n",
    "                    numFolds=10)\n",
    "\n",
    "model = cv.fit(train)\n",
    "train = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8966931996855348"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = model.getEvaluator()\n",
    "evaluator.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------------+----------+-----------+------------+-------------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|indexedEmbarked|indexedSex|bucketedAge|bucketedFare|    oneHotSex|oneHotEmbarked|   oneHotFare|    oneHotAge|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------------+----------+-----------+------------+-------------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|            2.0|       0.0|        2.0|         0.0|(1,[0],[1.0])|     (2,[],[])|(3,[0],[1.0])|(4,[2],[1.0])|(7,[0,3,5],[3.0,2...|[12.6615915716019...|[0.84410610477346...|       0.0|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|    7.0| null|       S|            0.0|       1.0|        2.0|         0.0|    (1,[],[])| (2,[0],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|[3.0,1.0,0.0,2.0,...|[6.68040618289554...|[0.44536041219303...|       1.0|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|          240276| 9.6875| null|       Q|            2.0|       0.0|        3.0|         1.0|(1,[0],[1.0])|     (2,[],[])|(3,[1],[1.0])|(4,[3],[1.0])|[2.0,0.0,0.0,3.0,...|[11.7630271159064...|[0.78420180772709...|       0.0|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0|          315154| 8.6625| null|       S|            0.0|       0.0|        1.0|         1.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[1],[1.0])|(7,[0,3,4],[3.0,1...|[13.2082496980383...|[0.88054997986922...|       0.0|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|         3101298|12.2875| null|       S|            0.0|       1.0|        1.0|         1.0|    (1,[],[])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[1],[1.0])|[3.0,1.0,1.0,1.0,...|[7.51187310879129...|[0.50079154058608...|       0.0|\n",
      "|        897|     3|Svensson, Mr. Joh...|  male|14.0|    0|    0|            7538|  9.225| null|       S|            0.0|       0.0|        0.0|         1.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[0],[1.0])| (7,[0,4],[3.0,1.0])|[12.1623912490498...|[0.81082608326999...|       0.0|\n",
      "|        898|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972| 7.6292| null|       Q|            2.0|       1.0|        1.0|         0.0|    (1,[],[])|     (2,[],[])|(3,[0],[1.0])|(4,[1],[1.0])|[3.0,0.0,0.0,1.0,...|[7.60538485918009...|[0.50702565727867...|       0.0|\n",
      "|        899|     2|Caldwell, Mr. Alb...|  male|26.0|    1|    1|          248738|   29.0| null|       S|            0.0|       0.0|        1.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|[2.0,1.0,1.0,1.0,...|[13.0449307239085...|[0.86966204826057...|       0.0|\n",
      "|        900|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657| 7.2292| null|       C|            1.0|       1.0|        1.0|         0.0|    (1,[],[])| (2,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|[3.0,0.0,0.0,1.0,...|[5.87570965633416...|[0.39171397708894...|       1.0|\n",
      "|        901|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871|  24.15| null|       S|            0.0|       0.0|        1.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|[3.0,2.0,0.0,1.0,...|[13.6506122724787...|[0.91004081816525...|       0.0|\n",
      "|        903|     1|Jones, Mr. Charle...|  male|46.0|    0|    0|             694|   26.0| null|       S|            0.0|       0.0|        2.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[2],[1.0])|(7,[0,3,4],[1.0,2...|[7.97467275539331...|[0.53164485035955...|       0.0|\n",
      "|        904|     1|Snyder, Mrs. John...|female|23.0|    1|    0|           21228|82.2667|  B45|       S|            0.0|       1.0|        1.0|         3.0|    (1,[],[])| (2,[0],[1.0])|    (3,[],[])|(4,[1],[1.0])|[1.0,1.0,0.0,1.0,...|[0.57700529015430...|[0.03846701934362...|       1.0|\n",
      "|        905|     2|Howard, Mr. Benjamin|  male|63.0|    1|    0|           24065|   26.0| null|       S|            0.0|       0.0|        3.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[3],[1.0])|[2.0,1.0,0.0,3.0,...|[11.8632791665135...|[0.79088527776757...|       0.0|\n",
      "|        906|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|            0.0|       1.0|        2.0|         3.0|    (1,[],[])| (2,[0],[1.0])|    (3,[],[])|(4,[2],[1.0])|[1.0,1.0,0.0,2.0,...|[0.55374947620082...|[0.03691663174672...|       1.0|\n",
      "|        907|     2|del Carlo, Mrs. S...|female|24.0|    1|    0|   SC/PARIS 2167|27.7208| null|       C|            1.0|       1.0|        1.0|         2.0|    (1,[],[])| (2,[1],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|[2.0,1.0,0.0,1.0,...|[1.77514696080559...|[0.11834313072037...|       1.0|\n",
      "|        908|     2|   Keane, Mr. Daniel|  male|35.0|    0|    0|          233734|  12.35| null|       Q|            2.0|       0.0|        2.0|         1.0|(1,[0],[1.0])|     (2,[],[])|(3,[1],[1.0])|(4,[2],[1.0])|[2.0,0.0,0.0,2.0,...|[13.1311187347058...|[0.87540791564705...|       0.0|\n",
      "|        909|     3|   Assaf, Mr. Gerios|  male|21.0|    0|    0|            2692|  7.225| null|       C|            1.0|       0.0|        1.0|         0.0|(1,[0],[1.0])| (2,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|(7,[0,3,5],[3.0,1...|[12.1184155305611...|[0.80789436870407...|       0.0|\n",
      "|        910|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270|  7.925| null|       S|            0.0|       1.0|        1.0|         1.0|    (1,[],[])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[1],[1.0])|[3.0,1.0,0.0,1.0,...|[7.33115301587607...|[0.48874353439173...|       1.0|\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|            2696|  7.225| null|       C|            1.0|       1.0|        2.0|         0.0|    (1,[],[])| (2,[1],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|[3.0,0.0,0.0,2.0,...|[5.63876332023789...|[0.37591755468252...|       1.0|\n",
      "|        912|     1|Rothschild, Mr. M...|  male|55.0|    1|    0|        PC 17603|   59.4| null|       C|            1.0|       0.0|        3.0|         3.0|(1,[0],[1.0])| (2,[1],[1.0])|    (3,[],[])|(4,[3],[1.0])|[1.0,1.0,0.0,3.0,...|[8.44121297712037...|[0.56274753180802...|       0.0|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------------+----------+-----------+------------+-------------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "test.select('PassengerId', 'prediction')\\\n",
    "    .coalesce(1)\\\n",
    "    .withColumn('Survived', test['prediction'].cast(IntegerType()))\\\n",
    "    .drop('prediction')\\\n",
    "    .write.csv('prediction.csv', header='true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('income').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# schema = StructType([\n",
    "#     StructField(\"age\", IntegerType(), True), \n",
    "#     StructField(\"workclass\", StringType(), True),\n",
    "#     StructField(\"fnlwgt\", FloatType(), True),\n",
    "#     StructField(\"education\", StringType(), True),\n",
    "#     StructField(\"education-num\", FloatType(), True),\n",
    "#     StructField(\"marital-status\", StringType(), True),\n",
    "#     StructField(\"occupation\", StringType(), True),\n",
    "#     StructField(\"relationship\", StringType(), True),\n",
    "#     StructField(\"race\", StringType(), True),\n",
    "#     StructField(\"sex\", StringType(), True),\n",
    "#     StructField(\"capital-gain\", FloatType(), True),\n",
    "#     StructField(\"capital-loss\", FloatType(), True),\n",
    "#     StructField(\"hours-per-week\", FloatType(), True),\n",
    "#     StructField(\"native-country\", StringType(), True),\n",
    "#     StructField(\"class\", StringType(), True)]\n",
    "# )\n",
    "\n",
    "# train = spark.read.csv('./adult.data.txt', schema=schema, inferSchema='true')\n",
    "\n",
    "headers = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "           \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "           \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\",\n",
    "           \"class\"]\n",
    "\n",
    "train = spark.read.csv('./adult.data.txt',\n",
    "                       inferSchema='true', \n",
    "                       ignoreLeadingWhiteSpace='true',\n",
    "                       ignoreTrailingWhiteSpace='true').toDF(*headers)\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, monotonically_increasing_id\n",
    "\n",
    "train = train.withColumn('index', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelCol = 'class'\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|<=50K|24720|\n",
      "| >50K| 7841|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby(labelCol).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is a class imbalance problem in our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def findMissingValuesCols(df):\n",
    "    numRows = df.count()\n",
    "    nullCols = []\n",
    "    for column in df.columns:\n",
    "        c = df.filter(col(column).isNotNull()).count()\n",
    "        if c != numRows:\n",
    "            nullCols.append(c)\n",
    "    return nullCols\n",
    "\n",
    "findMissingValuesCols(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 31|\n",
      "| 85|\n",
      "| 65|\n",
      "| 53|\n",
      "| 78|\n",
      "| 34|\n",
      "| 81|\n",
      "| 28|\n",
      "| 76|\n",
      "| 27|\n",
      "| 26|\n",
      "| 44|\n",
      "| 22|\n",
      "| 47|\n",
      "| 52|\n",
      "| 86|\n",
      "| 40|\n",
      "| 20|\n",
      "| 57|\n",
      "| 54|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('age').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "def crosstabPercentage(df, col1, col2):\n",
    "    ctabDf = df.crosstab(col1, col2)\n",
    "    ctabCol = col1 + '_' + col2\n",
    "    ctabNewCol = col1 + col2.title()\n",
    "    ctabDf = ctabDf.withColumn(ctabNewCol, ctabDf[ctabCol])\\\n",
    "                                         .orderBy(ctabNewCol).drop(ctabCol)\n",
    "    # Strip extra whitespaces from column name\n",
    "    for column in ctabDf.columns:\n",
    "        columnStripped = column.strip()\n",
    "        if column != columnStripped:\n",
    "            ctabDf = ctabDf.withColumn(column.strip(), ctabDf[column])\\\n",
    "                                         .drop(column)\n",
    "\n",
    "    ctabDf = ctabDf.withColumn('percentage-of->50K', ctabDf['>50K']/(ctabDf['<=50K']+ctabDf['>50K'])*100)\n",
    "    return ctabDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------------------+------------------+\n",
      "|<=50K|>50K|         raceClass|percentage-of->50K|\n",
      "+-----+----+------------------+------------------+\n",
      "|  246|  25|             Other|              9.23|\n",
      "|  275|  36|Amer-Indian-Eskimo|             11.58|\n",
      "| 2737| 387|             Black|             12.39|\n",
      "|20699|7117|             White|             25.59|\n",
      "|  763| 276|Asian-Pac-Islander|             26.56|\n",
      "+-----+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = crosstabPercentage(train, 'race', labelCol).orderBy('percentage-of->50K')\n",
    "df = df.orderBy('percentage-of->50K').withColumn('percentage-of->50K', \n",
    "                                    format_number(df['percentage-of->50K'], 2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------+------------------+\n",
      "|<=50K|>50K|ageClass|percentage-of->50K|\n",
      "+-----+----+--------+------------------+\n",
      "|  395|   0|      17|              0.00|\n",
      "|  550|   0|      18|              0.00|\n",
      "|  710|   2|      19|              0.28|\n",
      "|  753|   0|      20|              0.00|\n",
      "|  717|   3|      21|              0.42|\n",
      "|  752|  13|      22|              1.70|\n",
      "|  865|  12|      23|              1.37|\n",
      "|  767|  31|      24|              3.88|\n",
      "|  788|  53|      25|              6.30|\n",
      "|  722|  63|      26|              8.03|\n",
      "|  754|  81|      27|              9.70|\n",
      "|  748| 119|      28|             13.73|\n",
      "|  679| 134|      29|             16.48|\n",
      "|  690| 171|      30|             19.86|\n",
      "|  705| 183|      31|             20.61|\n",
      "|  639| 189|      32|             22.83|\n",
      "|  684| 191|      33|             21.83|\n",
      "|  643| 243|      34|             27.43|\n",
      "|  659| 217|      35|             24.77|\n",
      "|  635| 263|      36|             29.29|\n",
      "|  566| 292|      37|             34.03|\n",
      "|  545| 282|      38|             34.10|\n",
      "|  538| 278|      39|             34.07|\n",
      "|  526| 268|      40|             33.75|\n",
      "|  529| 279|      41|             34.53|\n",
      "|  510| 270|      42|             34.62|\n",
      "|  497| 273|      43|             35.45|\n",
      "|  443| 281|      44|             38.81|\n",
      "|  446| 288|      45|             39.24|\n",
      "|  445| 292|      46|             39.62|\n",
      "|  420| 288|      47|             40.68|\n",
      "|  326| 217|      48|             39.96|\n",
      "|  371| 206|      49|             35.70|\n",
      "|  341| 261|      50|             43.36|\n",
      "|  353| 242|      51|             40.67|\n",
      "|  286| 192|      52|             40.17|\n",
      "|  275| 189|      53|             40.73|\n",
      "|  242| 173|      54|             41.69|\n",
      "|  273| 146|      55|             34.84|\n",
      "|  248| 118|      56|             32.24|\n",
      "|  227| 131|      57|             36.59|\n",
      "|  244| 122|      58|             33.33|\n",
      "|  222| 133|      59|             37.46|\n",
      "|  211| 101|      60|             32.37|\n",
      "|  204|  96|      61|             32.00|\n",
      "|  191|  67|      62|             25.97|\n",
      "|  171|  59|      63|             25.65|\n",
      "|  155|  53|      64|             25.48|\n",
      "|  135|  43|      65|             24.16|\n",
      "|  115|  35|      66|             23.33|\n",
      "|  114|  37|      67|             24.50|\n",
      "|   93|  27|      68|             22.50|\n",
      "|   87|  21|      69|             19.44|\n",
      "|   70|  19|      70|             21.35|\n",
      "|   56|  16|      71|             22.22|\n",
      "|   58|   9|      72|             13.43|\n",
      "|   54|  10|      73|             15.62|\n",
      "|   39|  12|      74|             23.53|\n",
      "|   38|   7|      75|             15.56|\n",
      "|   41|   5|      76|             10.87|\n",
      "|   24|   5|      77|             17.24|\n",
      "|   18|   5|      78|             21.74|\n",
      "|   13|   9|      79|             40.91|\n",
      "|   20|   2|      80|              9.09|\n",
      "|   17|   3|      81|             15.00|\n",
      "|   12|   0|      82|              0.00|\n",
      "|    4|   2|      83|             33.33|\n",
      "|    9|   1|      84|             10.00|\n",
      "|    3|   0|      85|              0.00|\n",
      "|    1|   0|      86|              0.00|\n",
      "|    1|   0|      87|              0.00|\n",
      "|    3|   0|      88|              0.00|\n",
      "|   35|   8|      90|             18.60|\n",
      "+-----+----+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = crosstabPercentage(train, 'age', labelCol).orderBy('percentage-of->50K')\n",
    "df = df.orderBy('ageClass').withColumn('percentage-of->50K', \n",
    "                                    format_number(df['percentage-of->50K'], 2))\n",
    "df.show(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------+------------------+\n",
      "|<=50K|>50K|sexClass|percentage-of->50K|\n",
      "+-----+----+--------+------------------+\n",
      "| 9592|1179|  Female|             10.95|\n",
      "|15128|6662|    Male|             30.57|\n",
      "+-----+----+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = crosstabPercentage(train, 'sex', labelCol)\n",
    "df = df.orderBy('percentage-of->50K').withColumn('percentage-of->50K', \n",
    "                                    format_number(df['percentage-of->50K'], 2))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------+------------------+\n",
      "|<=50K|>50K|educationClass|percentage-of->50K|\n",
      "+-----+----+--------------+------------------+\n",
      "|   51|   0|     Preschool|              0.00|\n",
      "|  162|   6|       1st-4th|              3.57|\n",
      "|  317|  16|       5th-6th|              4.80|\n",
      "| 1115|  60|          11th|              5.11|\n",
      "|  487|  27|           9th|              5.25|\n",
      "|  606|  40|       7th-8th|              6.19|\n",
      "|  871|  62|          10th|              6.65|\n",
      "|  400|  33|          12th|              7.62|\n",
      "| 8826|1675|       HS-grad|             15.95|\n",
      "| 5904|1387|  Some-college|             19.02|\n",
      "|  802| 265|    Assoc-acdm|             24.84|\n",
      "| 1021| 361|     Assoc-voc|             26.12|\n",
      "| 3134|2221|     Bachelors|             41.48|\n",
      "|  764| 959|       Masters|             55.66|\n",
      "|  153| 423|   Prof-school|             73.44|\n",
      "|  107| 306|     Doctorate|             74.09|\n",
      "+-----+----+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = crosstabPercentage(train, 'education', labelCol).orderBy('percentage-of->50K')\n",
    "df = df.orderBy('percentage-of->50K').withColumn('percentage-of->50K', \n",
    "                                    format_number(df['percentage-of->50K'], 2))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+----+------------------+\n",
      "|education-numClassF|<=50K|>50K|percentage-of->50K|\n",
      "+-------------------+-----+----+------------------+\n",
      "|                1.0|   51|   0|              0.00|\n",
      "|                2.0|  162|   6|              3.57|\n",
      "|                3.0|  317|  16|              4.80|\n",
      "|                4.0|  606|  40|              6.19|\n",
      "|                5.0|  487|  27|              5.25|\n",
      "|                6.0|  871|  62|              6.65|\n",
      "|                7.0| 1115|  60|              5.11|\n",
      "|                8.0|  400|  33|              7.62|\n",
      "|                9.0| 8826|1675|             15.95|\n",
      "|               10.0| 5904|1387|             19.02|\n",
      "|               11.0| 1021| 361|             26.12|\n",
      "|               12.0|  802| 265|             24.84|\n",
      "|               13.0| 3134|2221|             41.48|\n",
      "|               14.0|  764| 959|             55.66|\n",
      "|               15.0|  153| 423|             73.44|\n",
      "|               16.0|  107| 306|             74.09|\n",
      "+-------------------+-----+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "educationNumClass = crosstabPercentage(train, 'education-num', labelCol)\n",
    "educationNumClass = educationNumClass.withColumn('percentage-of->50K', \n",
    "                                    format_number(educationNumClass['percentage-of->50K'], 2))\n",
    "educationNumClass = educationNumClass.withColumn('education-numClassF', educationNumClass['education-numClass'].cast(DoubleType()))\\\n",
    "                                     .orderBy('education-numClassF').drop('education-numClass')\n",
    "cols = educationNumClass.columns\n",
    "cols.remove('education-numClassF')\n",
    "cols.insert(0, 'education-numClassF')\n",
    "educationNumClass = educationNumClass.select(cols)\n",
    "educationNumClass.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+----+----+-------+-------+-------+---+----------+---------+---------+---------+-------+-------+---------+-----------+------------+\n",
      "|education-num_education|10th|11th|12th|1st-4th|5th-6th|7th-8th|9th|Assoc-acdm|Assoc-voc|Bachelors|Doctorate|HS-grad|Masters|Preschool|Prof-school|Some-college|\n",
      "+-----------------------+----+----+----+-------+-------+-------+---+----------+---------+---------+---------+-------+-------+---------+-----------+------------+\n",
      "|                      5|   0|   0|   0|      0|      0|      0|514|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                     10|   0|   0|   0|      0|      0|      0|  0|         0|        0|        0|        0|      0|      0|        0|          0|        7291|\n",
      "|                     14|   0|   0|   0|      0|      0|      0|  0|         0|        0|        0|        0|      0|   1723|        0|          0|           0|\n",
      "|                      1|   0|   0|   0|      0|      0|      0|  0|         0|        0|        0|        0|      0|      0|       51|          0|           0|\n",
      "|                      6| 933|   0|   0|      0|      0|      0|  0|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                      9|   0|   0|   0|      0|      0|      0|  0|         0|        0|        0|        0|  10501|      0|        0|          0|           0|\n",
      "|                     13|   0|   0|   0|      0|      0|      0|  0|         0|        0|     5355|        0|      0|      0|        0|          0|           0|\n",
      "|                      2|   0|   0|   0|    168|      0|      0|  0|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                     12|   0|   0|   0|      0|      0|      0|  0|      1067|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                      7|   0|1175|   0|      0|      0|      0|  0|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                      3|   0|   0|   0|      0|    333|      0|  0|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                     16|   0|   0|   0|      0|      0|      0|  0|         0|        0|        0|      413|      0|      0|        0|          0|           0|\n",
      "|                     11|   0|   0|   0|      0|      0|      0|  0|         0|     1382|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                      8|   0|   0| 433|      0|      0|      0|  0|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                      4|   0|   0|   0|      0|      0|    646|  0|         0|        0|        0|        0|      0|      0|        0|          0|           0|\n",
      "|                     15|   0|   0|   0|      0|      0|      0|  0|         0|        0|        0|        0|      0|      0|        0|        576|           0|\n",
      "+-----------------------+----+----+----+-------+-------+-------+---+----------+---------+---------+---------+-------+-------+---------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = train.crosstab('education-num', 'education')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that this is a sparse matrix, it's hard to find the non-zero values. So we will only focus on non-zero values to find out whether there is any relationship between these features and one of them is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"5_9th\": 514,\n",
      "    \"10_Some-college\": 7291,\n",
      "    \"14_Masters\": 1723,\n",
      "    \"1_Preschool\": 51,\n",
      "    \"6_10th\": 933,\n",
      "    \"9_HS-grad\": 10501,\n",
      "    \"13_Bachelors\": 5355,\n",
      "    \"2_1st-4th\": 168,\n",
      "    \"12_Assoc-acdm\": 1067,\n",
      "    \"7_11th\": 1175,\n",
      "    \"3_5th-6th\": 333,\n",
      "    \"16_Doctorate\": 413,\n",
      "    \"11_Assoc-voc\": 1382,\n",
      "    \"8_12th\": 433,\n",
      "    \"4_7th-8th\": 646,\n",
      "    \"15_Prof-school\": 576\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, lit, when\n",
    "\n",
    "iterator = df.toLocalIterator()\n",
    "d = {}\n",
    "for row in iterator:\n",
    "    rowDict = row.asDict()\n",
    "    educationNum = rowDict['education-num_education']\n",
    "    for k, v in rowDict.items():\n",
    "        if k != 'education-num_education' and v != 0:\n",
    "            d[educationNum+'_'+k] = v\n",
    "\n",
    "import json\n",
    "s = json.dumps(d, indent=4)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see it's obvious that these features are redundant. Only one of them should suffice for our classification task.\n",
    "\n",
    "Let's try more rigorous chi square test instead of something hand-wavy.\n",
    "\n",
    "First we will define an utility method that'll index the catgorical string columns, encodes them into one-hot-encoded vectors, and finally assemble all the feature vectos into once vector for later downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def autoIndexer(df, lableCol, outputCol='assembled'):\n",
    "    stringTypes = [dtype[0] for dtype in df.dtypes if dtype[1] == 'string']\n",
    "    indexedTypes = [stringType+'Indexed' for stringType in stringTypes]\n",
    "    try:\n",
    "        indexedTypes.remove(lableCol+'Indexed')\n",
    "    except:\n",
    "        pass\n",
    "    indexers = [StringIndexer(inputCol=stringType, outputCol=stringType+'Indexed') for stringType in stringTypes]\n",
    "    oheTypes = [indexedType+'OneHotEncoded' for indexedType in indexedTypes]\n",
    "    ohe = OneHotEncoderEstimator(inputCols=indexedTypes, outputCols=oheTypes)\n",
    "    assembler = VectorAssembler(inputCols=oheTypes, outputCol=outputCol)\n",
    "    pipeline = Pipeline(stages=[*indexers, ohe, assembler])    \n",
    "    indexed = pipeline.fit(df).transform(df)\n",
    "    return stringTypes, oheTypes, indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValues: [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexed = train.select('education-num', 'education')\n",
    "\n",
    "indexer = StringIndexer(inputCol='education', outputCol='educationIndexed')\n",
    "indexed = indexer.fit(indexed).transform(indexed)\n",
    "ohe = OneHotEncoderEstimator(inputCols=['education-num',], outputCols=['education-numOHE',])\n",
    "indexed = ohe.fit(indexed).transform(indexed)\n",
    "\n",
    "# The null hypothesis is that the occurrence of the outcomes is statistically independent.\n",
    "# In general, small p-values (1% to 5%) would cause you to reject the null hypothesis. \n",
    "# This very large p-value (92.65%) means that the null hypothesis should not be rejected.\n",
    "testResult = ChiSquareTest.test(indexed, 'education-numOHE', 'educationIndexed')\n",
    "r = testResult.head()\n",
    "print(\"pValues: \" + str(r.pValues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can accept the hypothesis that features are dependent. We will drop the 'education' feature since the info. is covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------------+------------------+\n",
      "|<=50K|>50K|  workclassClass|percentage-of->50K|\n",
      "+-----+----+----------------+------------------+\n",
      "|    7|   0|    Never-worked|              0.00|\n",
      "|   14|   0|     Without-pay|              0.00|\n",
      "| 1645| 191|               ?|             10.40|\n",
      "|17733|4963|         Private|             21.87|\n",
      "|  945| 353|       State-gov|             27.20|\n",
      "| 1817| 724|Self-emp-not-inc|             28.49|\n",
      "| 1476| 617|       Local-gov|             29.48|\n",
      "|  589| 371|     Federal-gov|             38.65|\n",
      "|  494| 622|    Self-emp-inc|             55.73|\n",
      "+-----+----+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = crosstabPercentage(train, 'workclass', labelCol).orderBy('percentage-of->50K')\n",
    "df = df.orderBy('percentage-of->50K').withColumn('percentage-of->50K', \n",
    "                                    format_number(df['percentage-of->50K'], 2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------------+------------------+\n",
      "|<=50K|>50K|hours-per-weekClass|percentage-of->50K|\n",
      "+-----+----+-------------------+------------------+\n",
      "|    1|   0|                 94|              0.00|\n",
      "|    1|   0|                 92|              0.00|\n",
      "|   14|   0|                 19|              0.00|\n",
      "|   11|   0|                 11|              0.00|\n",
      "|   21|   0|                 23|              0.00|\n",
      "|    5|   0|                 31|              0.00|\n",
      "|    1|   0|                 74|              0.00|\n",
      "|    6|   0|                 77|              0.00|\n",
      "|    3|   0|                 81|              0.00|\n",
      "|    1|   0|                 82|              0.00|\n",
      "|    2|   0|                 86|              0.00|\n",
      "|    1|   0|                 87|              0.00|\n",
      "|    2|   0|                 88|              0.00|\n",
      "|    3|   0|                 91|              0.00|\n",
      "|   38|   1|                  3|              2.56|\n",
      "|   29|   1|                 27|              3.33|\n",
      "|   28|   1|                 17|              3.45|\n",
      "|  389|  15|                 15|              3.71|\n",
      "|  639|  35|                 25|              5.19|\n",
      "|   17|   1|                  9|              5.56|\n",
      "+-----+----+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = crosstabPercentage(train, 'hours-per-week', labelCol).orderBy('percentage-of->50K')\n",
    "df = df.orderBy('percentage-of->50K').withColumn('percentage-of->50K', \n",
    "                                    format_number(df['percentage-of->50K'], 2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValues: [0.0,6.06621672894e-08,2.35683250693e-09,0.0,0.0073969884446,0.0,0.0,0.0350527043814,0.0,0.0,0.0,0.0,0.0,1.65423230669e-14,0.0,0.0232540498908,0.0,0.0,1.91608792943e-05,0.0,0.0,0.0,0.000106491974853,0.0,0.0,3.53831313693e-06,3.89777829346e-07,2.10630402009e-11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0571069627625,2.18791128326e-07,0.0,4.9695980664e-10,0.0,0.583599768678,0.0263766737841,0.0274947609427,0.035664584289,0.000697135482754,0.000169808165581,0.000192370213887,0.609920556916,0.0398097636079,0.0133898002533,0.392700772659,0.600053722635,0.0419896247007,3.21813000361e-05,0.00144941904399,0.000281102267653,0.0070067904419,0.459306125248,0.000198893471588,0.0114124246819,0.0199611745997,0.00636173094476,0.0589039315422,0.0130248843455,0.0216336827864,0.658726919143,0.0292840513559,0.225228126282,0.709716719993,0.535731237288,0.166902075353,0.193152005373,0.461796906847,0.197990667677,0.209235051547,0.0350527043814,0.166892320718,0.932513756806,0.940634568087]\n",
      "degreesOfFreedom: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "statistics: [200.793589887,29.3421367846,35.6538367078,199.110092586,7.17394620049,633.341426191,114.777660311,4.44260594562,6439.08982006,3301.82347925,525.134985304,180.170132045,134.963674236,58.900678515,1124.85597496,5.14942666541,1503.19108573,263.65946159,18.270931789,795.941125556,156.82781756,201.071459099,15.0179756445,247.958729102,87.7905645446,21.4999856345,25.7442933531,44.8693395273,5236.7622718,1156.93332393,1700.55873406,664.511306642,494.728585268,236.497542783,258.429468895,3.61947292524,26.8595445957,1518.88681996,38.6891658781,128.82801297,0.300451085709,4.93115555855,4.85947126794,4.41307083751,11.4968683265,14.1387650226,13.9041795752,0.26029063217,4.22597403483,6.11686578535,0.730562958268,0.274914879236,4.1356223585,17.2844299494,10.1418337637,13.1922961809,7.27122742572,0.547585046171,13.8415086027,6.39993959435,5.41528673504,7.44487578696,3.56797979712,6.16572687344,5.27500846001,0.19507373454,4.75083675643,1.47074538045,0.138560064385,0.383508997707,1.9105509116,1.69341045683,0.541535873405,1.6571344613,1.57671122595,4.44260594562,1.91063876643,0.00717113691731,0.00554612594902]\n"
     ]
    }
   ],
   "source": [
    "_, indexedTypes, indexedDf = autoIndexer(train, labelCol)\n",
    "# The null hypothesis is that the occurrence of the outcomes is statistically independent.\n",
    "# In general, small p-values (1% to 5%) would cause you to reject the null hypothesis. \n",
    "# This very large p-value (92.65%) means that the null hypothesis should not be rejected.\n",
    "testResult = ChiSquareTest.test(indexedDf, 'assembled', 'classIndexed')\n",
    "r = testResult.head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=2, featuresCol='assembled')\n",
    "model = kmeans.fit(indexedDf)\n",
    "indexedDf = model.transform(indexedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|prediction|classIndexed|\n",
      "+----------+------------+\n",
      "|         0|         0.0|\n",
      "|         1|         0.0|\n",
      "|         0|         0.0|\n",
      "|         1|         0.0|\n",
      "|         1|         0.0|\n",
      "|         1|         0.0|\n",
      "|         0|         0.0|\n",
      "|         1|         1.0|\n",
      "|         0|         1.0|\n",
      "|         1|         1.0|\n",
      "|         1|         1.0|\n",
      "|         1|         1.0|\n",
      "|         0|         0.0|\n",
      "|         0|         0.0|\n",
      "|         1|         1.0|\n",
      "|         1|         0.0|\n",
      "|         0|         0.0|\n",
      "|         0|         0.0|\n",
      "|         1|         0.0|\n",
      "|         0|         1.0|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedDf.select('prediction', 'classIndexed').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stringTypes = [dtype[0] for dtype in train.dtypes if dtype[1] == 'string']\n",
    "indexedTypes = [stringType+'Indexed' for stringType in stringTypes]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=stringType, outputCol=stringType+'Indexed', handleInvalid='skip') \\\n",
    "            for stringType in stringTypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: int, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, class: string, index: bigint, workclassIndexed: double, marital-statusIndexed: double, occupationIndexed: double, relationshipIndexed: double, raceIndexed: double, sexIndexed: double, native-countryIndexed: double, classIndexed: double, workclassIndexedOneHotEncoded: vector, raceIndexedOneHotEncoded: vector, occupationIndexedOneHotEncoded: vector, relationshipIndexedOneHotEncoded: vector, native-countryIndexedOneHotEncoded: vector, marital-statusIndexedOneHotEncoded: vector, sexIndexedOneHotEncoded: vector, classIndexedOneHotEncoded: vector, assembled: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "oheTypes = [indexedType+'OneHotEncoded' for indexedType in indexedTypes]\n",
    "ohe = OneHotEncoderEstimator(inputCols=indexedTypes, outputCols=oheTypes)\n",
    "\n",
    "# Fix columns\n",
    "oheTypes.remove('classIndexedOneHotEncoded')\n",
    "cols = train.columns[:]\n",
    "for oheType in oheTypes:\n",
    "    cols.append(oheType)\n",
    "for stringType in stringTypes:\n",
    "    cols.remove(stringType)\n",
    "\n",
    "cols.remove('index')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='assembled')\n",
    "classifier = GBTClassifier(featuresCol='assembled', labelCol='classIndexed')\n",
    "pipeline = Pipeline(stages=[*indexers, ohe, assembler, classifier])\n",
    "model = pipeline.fit(train)\n",
    "train = model.transform(train)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have class imbalance problem, that's why we will use area under ROC curve as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187387194685324"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='classIndexed', metricName='areaUnderROC')\n",
    "metric = evaluator.evaluate(train)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoderEstimator_40df83385e3f8afb8b61"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = model.stages[-1]\n",
    "ohe = model.stages[-3]\n",
    "ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| class|\n",
      "+------+\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "| >50K.|\n",
      "| >50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "| >50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "| >50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "| >50K.|\n",
      "| >50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "|<=50K.|\n",
      "| >50K.|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "           \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "           \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\",\n",
    "           \"class\"]\n",
    "\n",
    "test = spark.read.csv('./adult.test.txt',\n",
    "                      inferSchema='true', \n",
    "                      ignoreLeadingWhiteSpace='true',\n",
    "                      ignoreTrailingWhiteSpace='true').toDF(*headers)\n",
    "test.select('class').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the class labels in the test dataset are different than in train - '>50K' and '>50K.'. So we have to remove the extrac dot from the class label, before evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|class|\n",
      "+-----+\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "| >50K|\n",
      "| >50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "| >50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "| >50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "| >50K|\n",
      "| >50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "|<=50K|\n",
      "| >50K|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "stripDot = udf(lambda s: s[:-1], StringType())\n",
    "\n",
    "test = test.withColumn('classTrailed', stripDot(test['class'])).drop('class').withColumnRenamed('classTrailed', 'class')\n",
    "test.select('class').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104077343632521"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model.transform(test)\n",
    "metric = evaluator.evaluate(test)\n",
    "metric\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

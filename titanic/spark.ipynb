{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"titanic\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.csv('./train.csv', header=\"true\", inferSchema=\"true\")\n",
    "test = spark.read.csv('./test.csv', header=\"true\", inferSchema=\"true\")\n",
    "\n",
    "train.printSchema()\n",
    "test.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will explore missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 0.8013468013468014),\n",
       " ('Cabin', 0.22895622895622897),\n",
       " ('Embarked', 0.9977553310886644)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Find columns with missing values\n",
    "def findNullColumns(df):\n",
    "    nullCols = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        notNullCount = df.filter(col(k).isNotNull()).count()\n",
    "        if df.filter(col(k).isNotNull()).count() != numRows:\n",
    "            nullCols.append((k, notNullCount/numRows))\n",
    "    return nullCols\n",
    "\n",
    "findNullColumns(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see almost 80% of Cabin column is missing data. So we will drop the Cabin column.\n",
    "Very few data is missing in Embarked column. We will just drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "ageImputer = Imputer(inputCols=['Age'], outputCols=['imputedAge'], strategy='median')\n",
    "# ageImputer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = train.filter(train.Age.isNotNull())\n",
    "train = train.filter(train.Embarked.isNotNull())\n",
    "train = train.drop('Cabin')\n",
    "train.printSchema()\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next few sections, we will explore training data and the relationship between different features and labels.\n",
    "As we already know, most of passengers in Titanic didn't survive. Our training data suggests the same, around one-third of the passengers survived. Same goes for passenger class and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  340|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelCol = 'Survived'\n",
    "train.groupby(labelCol).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+\n",
      "|Survived_Sex|female|male|\n",
      "+------------+------+----+\n",
      "|           1|   231| 109|\n",
      "|           0|    81| 468|\n",
      "+------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Sex').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+---+---+\n",
      "|Survived_Pclass|  1|  2|  3|\n",
      "+---------------+---+---+---+\n",
      "|              1|134| 87|119|\n",
      "|              0| 80| 97|372|\n",
      "+---------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Pclass').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+---+---+\n",
      "|Survived_Embarked|  C|  Q|  S|\n",
      "+-----------------+---+---+---+\n",
      "|                1| 93| 30|217|\n",
      "|                0| 75| 47|427|\n",
      "+-----------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Embarked').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---+---+---+---+---+---+\n",
      "|Survived_SibSp|  0|  1|  2|  3|  4|  5|  8|\n",
      "+--------------+---+---+---+---+---+---+---+\n",
      "|             1|208|112| 13|  4|  3|  0|  0|\n",
      "|             0|398| 97| 15| 12| 15|  5|  7|\n",
      "+--------------+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'SibSp').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---+---+---+---+---+---+\n",
      "|Survived_Parch|  0|  1|  2|  3|  4|  5|  6|\n",
      "+--------------+---+---+---+---+---+---+---+\n",
      "|             1|231| 65| 40|  3|  0|  1|  0|\n",
      "|             0|445| 53| 40|  2|  4|  4|  1|\n",
      "+--------------+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.crosstab(labelCol, 'Parch').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValues: [0.0,0.0,6.02813466444e-06,4.02603175464e-07,4.93843854699e-11,0.0101897422598,0.0315461645121,4.25298058386e-05,0.00150622342036,0.612884928604,0.116808580457]\n",
      "degreesOfFreedom: [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "statistics: [100.980407261,260.756342249,20.4792462347,25.6818141585,43.2014376768,6.60142083307,4.62299205997,16.755010532,10.0709867693,0.255995235761,2.45959925254]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark.ml.feature import Bucketizer, OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorIndexer\n",
    "\n",
    "edaEmbarkedIndexer = StringIndexer(inputCol='Embarked', outputCol='indexedEmbarked')\n",
    "edaSexIndexer = StringIndexer(inputCol='Sex', outputCol='indexedSex')\n",
    "\n",
    "edaAgeImputer = Imputer(inputCols=['Age'], outputCols=['imputedAge'], strategy='median')\n",
    "\n",
    "ageSplits = [0, 16, 32, 48, 64, 200]\n",
    "edaAgeBucketizer = Bucketizer(splits=ageSplits, inputCol='imputedAge', outputCol='bucketedAge')\n",
    "\n",
    "fareSplits = [-float('inf'), 7.91, 14.454, 31, float('inf')]\n",
    "edaFareBucketizer = Bucketizer(splits=fareSplits, inputCol='Fare', outputCol='bucketedFare')\n",
    "\n",
    "oneHotEncoderEstimator = OneHotEncoderEstimator(inputCols=['indexedSex', 'indexedEmbarked', 'bucketedFare', 'bucketedAge'], \n",
    "                                                outputCols=['oneHotSex', 'oneHotEmbarked','oneHotFare', 'oneHotAge'])\n",
    "inputCols=['Pclass', 'oneHotSex', 'oneHotEmbarked','oneHotFare', 'oneHotAge']\n",
    "edaAssembler = VectorAssembler(inputCols=inputCols, outputCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages=[edaEmbarkedIndexer, edaSexIndexer, edaAgeImputer, edaAgeBucketizer, \n",
    "                            edaFareBucketizer, oneHotEncoderEstimator, edaAssembler])\n",
    "chiSqTrain = pipeline.fit(train).transform(train)\n",
    "\n",
    "r = ChiSquareTest.test(chiSqTrain, 'features', 'Survived').head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "embarkedIndexer = StringIndexer(inputCol='Embarked', outputCol='indexedEmbarked', handleInvalid='skip')\n",
    "sexFeatureIndexer = StringIndexer(inputCol='Sex', outputCol='indexedSex', handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "ageSplits = [0, 16, 32, 48, 64, 200]\n",
    "ageBucketizer = Bucketizer(splits=ageSplits, inputCol='imputedAge', outputCol='bucketedAge', handleInvalid='skip')\n",
    "fareSplits = [-float('inf'), 7.91, 14.454, 31, float('inf')]\n",
    "fareBucketizer = Bucketizer(splits=fareSplits, inputCol='Fare', outputCol='bucketedFare', handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "oneHotEncoderEstimator = OneHotEncoderEstimator(inputCols=['indexedSex', 'indexedEmbarked', 'bucketedFare', 'bucketedAge'], \n",
    "                                                outputCols=['oneHotSex', 'oneHotEmbarked','oneHotFare', 'oneHotAge'])\n",
    "assembler = VectorAssembler(inputCols=['Pclass', 'SibSp', 'Parch', 'bucketedAge', \n",
    "                                       'bucketedFare', 'indexedEmbarked', 'indexedSex'], outputCol='features')\n",
    "rf = RandomForestClassifier(labelCol=labelCol, featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[ageImputer, embarkedIndexer, sexFeatureIndexer, ageBucketizer, \n",
    "                            fareBucketizer, oneHotEncoderEstimator, assembler, rf])\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(rf.numTrees, [15, 20, 25, 30])\\\n",
    "                         .addGrid(rf.maxDepth, [5, 8])\\\n",
    "                         .build()\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=BinaryClassificationEvaluator(labelCol=labelCol, metricName='areaUnderROC'), \n",
    "                    numFolds=10)\n",
    "\n",
    "model = cv.fit(train)\n",
    "train = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9262562948676739"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = model.getEvaluator()\n",
    "evaluator.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+---------------+----------+-----------+------------+-------------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|imputedAge|indexedEmbarked|indexedSex|bucketedAge|bucketedFare|    oneHotSex|oneHotEmbarked|   oneHotFare|    oneHotAge|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+---------------+----------+-----------+------------+-------------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| null|       Q|      34.5|            2.0|       0.0|        2.0|         0.0|(1,[0],[1.0])|     (2,[],[])|(3,[0],[1.0])|(4,[2],[1.0])|(7,[0,3,5],[3.0,2...|[28.7330463692218...|[0.95776821230739...|       0.0|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|    7.0| null|       S|      47.0|            0.0|       1.0|        2.0|         0.0|    (1,[],[])| (2,[0],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|[3.0,1.0,0.0,2.0,...|[18.4419648085720...|[0.61473216028573...|       0.0|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|          240276| 9.6875| null|       Q|      62.0|            2.0|       0.0|        3.0|         1.0|(1,[0],[1.0])|     (2,[],[])|(3,[1],[1.0])|(4,[3],[1.0])|[2.0,0.0,0.0,3.0,...|[26.3896207345171...|[0.87965402448390...|       0.0|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0|          315154| 8.6625| null|       S|      27.0|            0.0|       0.0|        1.0|         1.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[1],[1.0])|(7,[0,3,4],[3.0,1...|[25.4050039801176...|[0.84683346600392...|       0.0|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|         3101298|12.2875| null|       S|      22.0|            0.0|       1.0|        1.0|         1.0|    (1,[],[])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[1],[1.0])|[3.0,1.0,1.0,1.0,...|[20.6092016331150...|[0.68697338777050...|       0.0|\n",
      "|        897|     3|Svensson, Mr. Joh...|  male|14.0|    0|    0|            7538|  9.225| null|       S|      14.0|            0.0|       0.0|        0.0|         1.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[0],[1.0])| (7,[0,4],[3.0,1.0])|[17.5086094166613...|[0.58362031388871...|       0.0|\n",
      "|        898|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972| 7.6292| null|       Q|      30.0|            2.0|       1.0|        1.0|         0.0|    (1,[],[])|     (2,[],[])|(3,[0],[1.0])|(4,[1],[1.0])|[3.0,0.0,0.0,1.0,...|[7.91034524226694...|[0.26367817474223...|       1.0|\n",
      "|        899|     2|Caldwell, Mr. Alb...|  male|26.0|    1|    1|          248738|   29.0| null|       S|      26.0|            0.0|       0.0|        1.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|[2.0,1.0,1.0,1.0,...|[24.5469152307387...|[0.81823050769129...|       0.0|\n",
      "|        900|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657| 7.2292| null|       C|      18.0|            1.0|       1.0|        1.0|         0.0|    (1,[],[])| (2,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|[3.0,0.0,0.0,1.0,...|[7.20270339259818...|[0.24009011308660...|       1.0|\n",
      "|        901|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871|  24.15| null|       S|      21.0|            0.0|       0.0|        1.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|[3.0,2.0,0.0,1.0,...|[26.5371830067386...|[0.88457276689128...|       0.0|\n",
      "|        902|     3|    Ilieff, Mr. Ylio|  male|null|    0|    0|          349220| 7.8958| null|       S|      28.0|            0.0|       0.0|        1.0|         0.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])| (7,[0,3],[3.0,1.0])|[26.9913751001323...|[0.89971250333774...|       0.0|\n",
      "|        903|     1|Jones, Mr. Charle...|  male|46.0|    0|    0|             694|   26.0| null|       S|      46.0|            0.0|       0.0|        2.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[2],[1.0])|(7,[0,3,4],[1.0,2...|[13.2257870231226...|[0.44085956743742...|       1.0|\n",
      "|        904|     1|Snyder, Mrs. John...|female|23.0|    1|    0|           21228|82.2667|  B45|       S|      23.0|            0.0|       1.0|        1.0|         3.0|    (1,[],[])| (2,[0],[1.0])|    (3,[],[])|(4,[1],[1.0])|[1.0,1.0,0.0,1.0,...|[0.49166666666666...|[0.01638888888888...|       1.0|\n",
      "|        905|     2|Howard, Mr. Benjamin|  male|63.0|    1|    0|           24065|   26.0| null|       S|      63.0|            0.0|       0.0|        3.0|         2.0|(1,[0],[1.0])| (2,[0],[1.0])|(3,[2],[1.0])|(4,[3],[1.0])|[2.0,1.0,0.0,3.0,...|[27.6929862291704...|[0.92309954097234...|       0.0|\n",
      "|        906|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|      47.0|            0.0|       1.0|        2.0|         3.0|    (1,[],[])| (2,[0],[1.0])|    (3,[],[])|(4,[2],[1.0])|[1.0,1.0,0.0,2.0,...|[0.28055555555555...|[0.00935185185185...|       1.0|\n",
      "|        907|     2|del Carlo, Mrs. S...|female|24.0|    1|    0|   SC/PARIS 2167|27.7208| null|       C|      24.0|            1.0|       1.0|        1.0|         2.0|    (1,[],[])| (2,[1],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|[2.0,1.0,0.0,1.0,...|[4.27154952890247...|[0.14238498429674...|       1.0|\n",
      "|        908|     2|   Keane, Mr. Daniel|  male|35.0|    0|    0|          233734|  12.35| null|       Q|      35.0|            2.0|       0.0|        2.0|         1.0|(1,[0],[1.0])|     (2,[],[])|(3,[1],[1.0])|(4,[2],[1.0])|[2.0,0.0,0.0,2.0,...|[25.0101711326537...|[0.83367237108845...|       0.0|\n",
      "|        909|     3|   Assaf, Mr. Gerios|  male|21.0|    0|    0|            2692|  7.225| null|       C|      21.0|            1.0|       0.0|        1.0|         0.0|(1,[0],[1.0])| (2,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|(7,[0,3,5],[3.0,1...|[25.5485144708741...|[0.85161714902913...|       0.0|\n",
      "|        910|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270|  7.925| null|       S|      27.0|            0.0|       1.0|        1.0|         1.0|    (1,[],[])| (2,[0],[1.0])|(3,[1],[1.0])|(4,[1],[1.0])|[3.0,1.0,0.0,1.0,...|[23.8030901912650...|[0.79343633970883...|       0.0|\n",
      "|        911|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|            2696|  7.225| null|       C|      45.0|            1.0|       1.0|        2.0|         0.0|    (1,[],[])| (2,[1],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|[3.0,0.0,0.0,2.0,...|[18.7452890065505...|[0.62484296688501...|       0.0|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+---------------+----------+-----------+------------+-------------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "csvPath = 'prediction.csv'\n",
    "\n",
    "if not os.path.exists(csvPath):\n",
    "    test.select('PassengerId', 'prediction')\\\n",
    "        .coalesce(1)\\\n",
    "        .withColumn('Survived', test['prediction'].cast(IntegerType()))\\\n",
    "        .drop('prediction')\\\n",
    "        .write.csv(csvPath, header='true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
